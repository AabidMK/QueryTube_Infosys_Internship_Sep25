# -*- coding: utf-8 -*-
"""DataCleaningandDataVisual.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uT4eYaBqJY_CaS1LpxhalPF1UlSDwBDP
"""

!pip install youtube-transcript-api

"""# Task
Analyze the provided YouTube data in the file "/content/YT_UR_DATA.csv" by performing data cleaning, exploratory data analysis (EDA), and data visualization to gain insights into the data.

## Load the data

### Subtask:
Load the `YT_UR_DATA.csv` file into a pandas DataFrame.

**Reasoning**:
Load the data from the CSV file into a pandas DataFrame and display the head to verify the loading.
"""

df = pd.read_csv("YT_UR_DATA.csv")
display(df.head())

"""## Data cleaning

### Subtask:
Clean the data by handling missing values, converting data types (e.g., `publishedAt` to datetime), and addressing any inconsistencies.

**Reasoning**:
Inspect the DataFrame to understand the data types and identify missing values for cleaning.
"""

display(df.info())
display(df.isnull().sum())

"""**Reasoning**:
Convert 'publishedAt' to datetime, numeric columns to appropriate types, handle missing values in 'description' and 'transcript', and convert 'tags' to a list, as identified in the previous step.


"""

df['publishedAt'] = pd.to_datetime(df['publishedAt'])

numeric_cols = ['viewCount', 'likeCount', 'favoriteCount', 'commentCount', 'channel_subscriberCount', 'channel_videoCount']
for col in numeric_cols:
    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)

df['description'] = df['description'].fillna('')
df['transcript'] = df['transcript'].fillna('')

import ast
df['tags'] = df['tags'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])

display(df.info())
display(df.isnull().sum())

display(df.describe())
display(df['categoryId'].value_counts())
display(df[['viewCount', 'likeCount', 'commentCount']].corr())
display(df['duration'].value_counts())

non_empty_transcripts = df[df['transcript'].str.strip() != '']['transcript'].head()
for i, transcript in enumerate(non_empty_transcripts):
    print(f"--- Transcript {i+1} ---")
    print(transcript)
    print("\n")

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(12, 6))
sns.lineplot(data=df, x='publishedAt', y='viewCount')
plt.title('View Count Trend Over Time')
plt.xlabel('Published Date')
plt.ylabel('View Count')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

plt.figure(figsize=(12, 6))
sns.lineplot(data=df, x='publishedAt', y='likeCount')
plt.title('Like Count Trend Over Time')
plt.xlabel('Published Date')
plt.ylabel('Like Count')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

plt.figure(figsize=(12, 6))
sns.lineplot(data=df, x='publishedAt', y='commentCount')
plt.title('Comment Count Trend Over Time')
plt.xlabel('Published Date')
plt.ylabel('Comment Count')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

transcript_df = pd.read_csv("ChannelTranscripts.csv", dtype={'video_id': str})

merged_df = df.drop('transcript', axis=1).merge(transcript_df, left_on='id', right_on='video_id', how='left')

display(merged_df.head())

videos_with_transcripts = merged_df[
    (merged_df['transcript'].str.strip() != '') &
    (merged_df['transcript'] != 'Transcript not available') &
    (~merged_df['transcript'].str.startswith('Error:'))
]

print(f"\nNumber of videos with available transcripts: {len(videos_with_transcripts)}")

print("\nSample transcripts:")
for i, row in videos_with_transcripts.head().iterrows():
    print(f"\n--- Transcript for video ID: {row['id']} ---")
    print(row['transcript'])